# 全局配置
global:
  log:
    level: "info"         # 日志级别: debug, info, warning, error
    format: "text"        # 日志格式: text 或 json
    output: "console"     # 日志输出: console 或 file
    file_path: "./logs/ai_dataflux.log"  # 当output=file时有效
  flux_api_url: http://127.0.0.1:8787    # Flux API端点URL

# 数据源类型配置
datasource:
  type: excel   # 明确指定使用Excel数据源
  concurrency:  # 将并发配置移至此处，便于程序统一处理
    max_workers: 1000
    batch_size: 1000
    save_interval: 1800    # Excel文件保存间隔
    retry_times: 1
    backoff_factor: 3
    shard_size: 100000     # 默认分片大小
    min_shard_size: 1000  # 最小分片大小
    max_shard_size: 200000 # 最大分片大小
    api_pause_duration: 1.0       # API错误时全局暂停秒数 (可选, 默认 2.0)
    api_error_trigger_window: 1.0     # 多少秒内的API错误才会触发暂停 (可选, 默认 2.0)
    max_connections: 2500            # aiohttp的最大并发连接数 (可选, 默认 1000)
    max_connections_per_host: 0      # 对每个主机的最大并发连接数 (可选, 0表示无限制)
    retry_limits:
      api_error: 10      # API错误最多重试10次
      content_error: 10    # 内容错误最多重试10次
      system_error: 10    # 系统错误最多重试10次

# MySQL数据源配置（仅当type=mysql时有效）
mysql:
  host: "localhost"
  port: 3306
  user: "root"
  password: "your_password"
  database: "ai_tasks"
  table_name: "tasks"

# Excel数据源配置（仅当type=excel时有效）
excel:
  input_path: "./data/input.xlsx"
  output_path: "./data/output.xlsx"

# 需要从表中提取的字段
columns_to_extract:
  - "question"
  - "context"

# 需要写回表的字段(别名->真实字段名)
columns_to_write:
  answer: "ai_answer"
  category: "ai_category" 
  confidence: "ai_confidence"
  sentiment: "ai_sentiment"

# 字段值验证配置
validation:
  enabled: true
  field_rules:
    category:
      - "technical"
      - "business"
      - "general"
    sentiment:
      - "positive"
      - "neutral"
      - "negative"

# 模型配置
models:
  - id: 1
    name: "model-1"
    model: "gpt-4-turbo"
    channel_id: "1"
    api_key: "your_api_key_1"
    timeout: 300
    weight: 10
    temperature: 0.3
    safe_rps: 5  # 每秒安全请求数
    supports_json_schema: true

  - id: 2
    name: "model-2"
    model: "claude-3-opus"
    channel_id: "2"
    api_key: "your_api_key_2"
    timeout: 300
    weight: 5
    temperature: 0.3
    safe_rps: 3
    supports_json_schema: true

  - id: 3
    name: "model-3"
    model: "llama-3-70b"
    channel_id: "3"
    api_key: "your_api_key_3"
    timeout: 300
    weight: 3
    temperature: 0.3
    safe_rps: 10
    supports_json_schema: false

# 通道配置
channels:
  "1":
    name: "openai-api"
    base_url: "https://api.openai.com"
    api_path: "/v1/chat/completions"
    timeout: 300
    proxy: ""  # 可选代理设置，例如 "http://127.0.0.1:7890"


# 提示词配置
prompt:
  required_fields:
    - "answer"
    - "category"
    - "confidence"
    - "sentiment"
  use_json_schema: true
  temperature: 0.3  # 较低温度确保分类准确性
  system_prompt: |
    你是一个专业的数据分析师，擅长从复杂数据中提取有价值的信息。请根据提供的数据和上下文，给出准确、深入的分析和建议。
  template: |
    请分析以下数据并提供专业的回答:

    {record_json}
    
    系统要求:
    1. 请详细分析问题和上下文，提供准确、有深度的回答
    2. 回答应专业、清晰、有条理，避免冗余内容
    3. 必须返回JSON格式的结果，包含以下字段:
       - answer: 详细的回答内容
       - category: 问题类别，可选值为 "technical"、"business"、"general"
       - confidence: 置信度评分，范围0-100的整数
       - sentiment: 情感倾向，可选值为 "positive"、"neutral"、"negative"
    
    格式示例:
    {
      "answer": "这里是详细的回答内容...",
      "category": "technical",
      "confidence": 95,
      "sentiment": "neutral"
    }
    
    请确保回答是JSON格式，且仅包含JSON内容，不需要额外的解释文字。
