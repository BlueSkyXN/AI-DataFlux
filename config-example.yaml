# 全局配置
global:
  log:
    level: "info"         # 日志级别: debug, info, warning, error
    format: "text"        # 日志格式: text 或 json
    output: "console"     # 日志输出: console 或 file
    file_path: "./logs/ai_dataflux.log"  # 当output=file时有效
  flux_api_url: http://127.0.0.1:8787    # Flux API端点URL

# 网关配置
gateway:
  max_connections: 1000          # 网关到上游的总并发连接上限
  max_connections_per_host: 1000 # 单个上游主机的并发连接上限

# 数据源类型配置
datasource:
  type: excel   # 数据源类型: mysql 或 excel
  
  # === 高性能引擎配置 ===
  # 引擎类型: auto (自动选择) | pandas (默认) | polars (高性能)
  # auto: 优先使用 polars (如已安装)，否则回退到 pandas
  engine: auto
  
  # Excel 读取器: auto | openpyxl (默认) | calamine (高性能，需安装 fastexcel)
  # calamine: 基于 Rust 的读取器，速度提升 10-50x
  excel_reader: auto
  
  # Excel 写入器: auto | openpyxl (默认) | xlsxwriter (高性能)
  # xlsxwriter: 写入速度提升 2-5x
  excel_writer: auto
  
  require_all_input_fields: true  # 输入字段检查: true=全部非空才处理, false=至少一个非空即可
  concurrency:
    batch_size: 100        # 批处理大小（也用作最大并发任务数）
    save_interval: 300     # Excel文件保存间隔（秒）
    shard_size: 10000      # 默认分片大小
    min_shard_size: 1000   # 最小分片大小
    max_shard_size: 50000  # 最大分片大小
    api_pause_duration: 2.0        # API错误时全局暂停秒数
    api_error_trigger_window: 2.0  # 多少秒内的API错误才会触发暂停
    max_connections: 1000          # aiohttp的最大并发连接数
    max_connections_per_host: 0    # 对每个主机的最大并发连接数（0表示无限制）
    retry_limits:                  # 按错误类型配置重试次数
      api_error: 3                 # API错误（超时、HTTP错误）最多重试次数
      content_error: 1             # 内容错误（JSON解析失败）最多重试次数
      system_error: 2              # 系统错误（内部异常）最多重试次数

# MySQL数据源配置（仅当type=mysql时有效）
mysql:
  host: "localhost"
  port: 3306
  user: "root"
  password: "your_password"
  database: "ai_tasks"
  table_name: "tasks"
  pool_size: 10                   # 数据库连接池大小（默认为batch_size的1/10）

# Excel数据源配置（仅当type=excel时有效）
excel:
  input_path: "./data/input.xlsx"
  output_path: "./data/output.xlsx"

# PostgreSQL数据源配置（仅当type=postgresql时有效）
postgresql:
  host: "localhost"
  port: 5432
  user: "postgres"
  password: "your_password"
  database: "ai_tasks"
  table_name: "tasks"
  schema_name: "public"           # 可选，默认为 public
  pool_size: 10                   # 连接池大小（默认为batch_size的1/10）

# SQLite数据源配置（仅当type=sqlite时有效）
sqlite:
  db_path: "./data/tasks.db"      # 数据库文件路径
  table_name: "tasks"

# CSV数据源配置（仅当type=csv时有效）
csv:
  input_path: "./data/input.csv"
  output_path: "./data/output.csv"  # 可选，默认为 input_path
  encoding: "utf-8"               # 可选，默认为 utf-8

# 需要从表中提取的字段
columns_to_extract:
  - "question"
  - "context"

# 需要写回表的字段(别名->真实字段名)
columns_to_write:
  answer: "ai_answer"
  category: "ai_category" 
  confidence: "ai_confidence"
  sentiment: "ai_sentiment"

# 字段值验证配置
validation:
  enabled: true
  field_rules:
    category:
      - "technical"
      - "business"
      - "general"
    sentiment:
      - "positive"
      - "neutral"
      - "negative"

# 模型配置
models:
  - id: 1
    name: "model-1"               # 模型显示名称
    model: "gpt-4-turbo"          # 实际模型标识符
    channel_id: "1"               # 所属通道ID
    api_key: "your_api_key_1"     # API密钥
    timeout: 300                  # 超时时间（秒）
    weight: 10                    # 调度权重（使用加权随机算法）
    temperature: 0.3              # 模型温度
    safe_rps: 5                   # 每秒安全请求数（令牌桶限流）
    supports_json_schema: true    # 是否支持JSON Schema输出格式
    supports_advanced_params: true  # 是否支持高级参数（presence_penalty等）

  - id: 2
    name: "model-2"
    model: "claude-3-opus"
    channel_id: "2"
    api_key: "your_api_key_2"
    timeout: 300
    weight: 5
    temperature: 0.3
    safe_rps: 3
    supports_json_schema: true
    supports_advanced_params: false

  - id: 3
    name: "model-3"
    model: "llama-3-70b"
    channel_id: "3"
    api_key: "your_api_key_3"
    timeout: 300
    weight: 3
    temperature: 0.3
    safe_rps: 10
    supports_json_schema: false
    supports_advanced_params: false

# 通道配置
channels:
  "1":
    name: "openai-api"
    base_url: "https://api.openai.com"
    api_path: "/v1/chat/completions"
    timeout: 300
    proxy: ""         # 可选代理设置，例如 "http://127.0.0.1:7890"
    ssl_verify: true  # SSL证书验证开关，Mac上遇到证书问题可设为false

    # IP 池配置 (可选) - 用于多 IP 均匀负载和故障回退
    # 当域名有多个可用 IP 时，使用轮询策略均匀分配请求到不同 IP
    # 注意: 配置了 proxy 时 ip_pool 将被忽略
    # ip_pool:
    #   - "1.2.3.4"    # 第一个 IP
    #   - "1.2.3.5"    # 第二个 IP
    #   - "1.2.3.6"    # 第三个 IP (可以配置更多)


# 提示词配置
prompt:
  required_fields:
    - "answer"
    - "category"
    - "confidence"
    - "sentiment"
  use_json_schema: true
  temperature: 0.3  # 较低温度确保分类准确性
  system_prompt: |
    你是一个专业的数据分析师，擅长从复杂数据中提取有价值的信息。请根据提供的数据和上下文，给出准确、深入的分析和建议。
  template: |
    请分析以下数据并提供专业的回答:

    {record_json}
    
    系统要求:
    1. 请详细分析问题和上下文，提供准确、有深度的回答
    2. 回答应专业、清晰、有条理，避免冗余内容
    3. 必须返回JSON格式的结果，包含以下字段:
       - answer: 详细的回答内容
       - category: 问题类别，可选值为 "technical"、"business"、"general"
       - confidence: 置信度评分，范围0-100的整数
       - sentiment: 情感倾向，可选值为 "positive"、"neutral"、"negative"
    
    格式示例:
    {
      "answer": "这里是详细的回答内容...",
      "category": "technical",
      "confidence": 95,
      "sentiment": "neutral"
    }
    
    请确保回答是JSON格式，且仅包含JSON内容，不需要额外的解释文字。

# Token 估算配置 (可选)
token_estimation:
  mode: io               # 估算模式:
                         #   in  - 输入 token
                         #   out - 输出 token
                         #   io  - 输入+输出
  sample_size: -1         # -1=全量计算(忽略处理状态), >0=采样数量
  encoding: o200k_base    # 固定使用最新编码器
  # tiktoken_model: gpt-4o  # 可选: 当未指定 encoding 时用于选择编码器
